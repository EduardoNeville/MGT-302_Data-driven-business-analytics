{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data driven business analytics - Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3. Causal discovery\n",
    "In this notebook you will have to implement a simplified version of PC algorithm for causal discovery. To do this, you need to implement the following methods:\n",
    "  - `get_partial_correlation` - computes the partial correlation between two random variables X and Y given a third variable Z\n",
    "  - `identify_skeleton` - computes the skeleton of the causal graph $G$ from the correlation matrix computed over the random variables from the graph\n",
    "  -  `identify_v_structures` - finds v-structures in the graph $G$ from a skeleton and from the records of conditional dependences between all pairs of variables\n",
    "  - `Meek_rule1` - applies the first Meek orientation rule to orient more edges in the learned graph (see below)\n",
    "  - `Meek_rule2` - applies the second Meek orientation rule to orient more edges in the learned graph (see below)\n",
    "  - `Meek_rule3` - applies the third Meek orientation rule to orient more edges in the learned graph (see below)\n",
    "  - `PC` - aggregates all previous methods and runs the (simplified) PC algorithm for causal discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start with some useful packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying the skeleton via conditional independence tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core tools for the PC algorithm are conditional independence tests. In general, the task of deciding whether the random variables $X$ and $Y$ are conditionally independent given a set of random variables $\\mathbf{Z}$, from a finite number of samples, is challenging.\n",
    "\n",
    "In this notebook we will consider a simplified version of the PC algorithm, where criterions for conditional independence are simplified as follows.\n",
    "\n",
    "  1. Only tests for $X \\perp Y$ (unconditioned joint independence) or $X \\perp Y \\mid Z$ (joint independence conditioned to only *one* variable) will be considered.\n",
    "  \n",
    "  2. The statistical criterion for declaring that $X$ is independent from $Y$ will be $cor(X, Y) < \\alpha$, where $cor(X, Y)$ is the correlation, and the significance level $\\alpha$ can be taken to be $0.05$.\n",
    "  \n",
    "  3. The statistical criterion for declaring that $X$ is independent from $Y$ given $Z$ will be $cor(X, Y \\mid Z) < \\alpha$, where $cor(X, Y)$ is the partial correlation, and the significance level $\\alpha$ can be taken to be $0.05$. For more details on how to compute partial correlation, have a look at this [wiki link](https://en.wikipedia.org/wiki/Partial_correlation), where the partial correlation is denoted by $\\rho_{XY\\cdot Z}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the first function we ask you to implement is `get_partial_correlation`, which computes this partial correlation $cor(X, Y \\mid Z)$ from the correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partial_correlation(x_id, y_id, z_id, corr_matrix):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        x_id - id of random variable X in correlation matrix corr_matrix (int)\n",
    "        y_id - id of random variable Y in correlation matrix corr_matrix (int)\n",
    "        z_id - id of random variable Z in correlation matrix corr_matrix (int)\n",
    "        corr_matrix - correlation matrix for the features (2-dimensional np.array)\n",
    "    Return:\n",
    "        res - partial correlation between random variables X and Y given controlling variable Z (float)\n",
    "    \"\"\"\n",
    "    ############################################################################\n",
    "    # TODO: Compute partial correlation between random variables X and Y       #\n",
    "    #    conditional to variable Z.                                            #\n",
    "    ############################################################################\n",
    "    # Replace \"...\" with your code\n",
    "    \n",
    "    res = ...\n",
    "\n",
    "    ############################################################################\n",
    "    #                               END OF YOUR CODE                           #\n",
    "    ############################################################################\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of the PC algorithm is to find the skeleton of the causal graph $G$. For this, you need to implement the function `identify_skeleton`, which takes as input:\n",
    "- `adj_matrix` - adjacency matrix that in the begininning represent the fully connected graph;\n",
    "- `corr_matrix` - correlation matrix between all variables in graph $G$;\n",
    "- `alpha` - significance level.\n",
    "\n",
    "The function should iterate through all pairs of the variables in graph $G$, i.e. $X_i, X_j$ and check whether $X_i$ is independent from $X_j$ or whether there exists a variable $X_k\\neq X_i, X_j$ such that $X_i \\perp  X_j \\mid X_k$. Then, if $X_i \\perp X_j \\mid X_k$ or $X_i \\perp X_j$ then there is no edge between $X_i$ and $X_j$ in the graph $G$.\n",
    "\n",
    "Additionally, for any pair of variables $(X_i, X_j)$ you will need to store all variables $X_k$ into the dictionary `dependencies` such that:\n",
    "  - $X_k\\neq X_i, X_j$;\n",
    "  - $X_i \\not\\perp X_j \\mid X_k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example of what `dependencies` should contain, if $X_i, X_j, X_{k_1}, X_{k_2}, X_{k_3}$ are such that $i<j$ and\n",
    "  - $X_{k_1}\\neq X_i, X_j$ and $X_{k_2}\\neq X_i, X_j$, $X_{k_3}\\neq X_i, X_j$\n",
    "  - $X_i \\not\\perp X_j \\mid X_{k_1}$ and $X_i \\not\\perp X_j \\mid X_{k_2}$, and $X_i \\perp X_j \\mid X_{k_3}$.\n",
    "  \n",
    "Then dictionary `dependencies` will contain $\\{(i, j): [k_1, k_2] \\}$, where tuple $(i, j)$ is a key and $[k_1, k_2]$ is the list of all indices $k$ that was mentioned before. \n",
    "\n",
    "Note that the keys of dictionary `dependencies` are the ordered pair of integers $(i, j)$, i.e. $i < j$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_skeleton(adj_matrix, corr_matrix, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        adj_matrix - adjacency matrix (2-dimensional np.array) \n",
    "        corr_matrix - correlation matrix of the random variables in DAG (2-dimensional np.array)\n",
    "        alpha - significance level (float)\n",
    "    Return:\n",
    "        adj_matrix - updated adjacency matrix (2-dimenstional np.array)\n",
    "        dependencies - a dictionary that for each pair of random variables (X, Y) stores all \n",
    "                variables Z that make X, Y conditionally dependent.\n",
    "    \"\"\"\n",
    "    ############################################################################\n",
    "    # TODO: Find the skeleton structure and update adj_matrix accordingly.     #\n",
    "    ############################################################################\n",
    "    # Replace \"...\" with your code\n",
    "\n",
    "    adj_matrix = ...\n",
    "    dependencies = ...\n",
    "\n",
    "    ############################################################################\n",
    "    #                               END OF YOUR CODE                           #\n",
    "    ############################################################################\n",
    "    \n",
    "    return adj_matrix, dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the v-structures\n",
    "In a second step, we need to implement a function which finds all *v-structures* in the skeleton of the graph $G$.\n",
    "\n",
    "*Hint:* You don't need to perform any other conditional independence tests. Dictionary `dependencies` which was defined above is all you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_v_structures(adj_matrix, dependencies):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        adj_matrix - adjacency matrix (2-dimensional np.array) \n",
    "        dependencies - a dictionary that for each pair of random variables (X, Y) stores all \n",
    "                variables Z that make X, Y conditionally dependent.\n",
    "    Return:\n",
    "        adj_matrix - updated adjacency matrix (2-dimenstional np.array)\n",
    "    \"\"\"\n",
    "    ############################################################################\n",
    "    # TODO: Find all v-structures in the graph and orient the edges in         #\n",
    "    #   adjacency matrix accordingly.                                          #\n",
    "    ############################################################################\n",
    "    # Replace \"...\" with your code\n",
    "    \n",
    "    adj_matrix = ...\n",
    "\n",
    "    ############################################################################\n",
    "    #                               END OF YOUR CODE                           #\n",
    "    ############################################################################\n",
    "    \n",
    "    return adj_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meek orientation rules\n",
    "In the lectures, we saw that after obtaining the skeleton and the v-structures, some more edges could be oriented.\n",
    "The rules that enable new edges to get oriented are called Meek rules and are presented hereafter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First Rule**\\\n",
    "Assume there are three random variables $A$, $B$, $C$ such that\n",
    "- an edge between $A$ and $B$ is oriented from $A$ to $B$,\n",
    "- an edge between $B$ and $C$ is not oriented,\n",
    "- there is no edge from $A$ to $C$,\n",
    "\n",
    "then the edge between $B$ and $C$ can be oriented from $B$ to $C$.\n",
    "\n",
    "The following picture gives an illustration of this First Rule.\\\n",
    "![](Rule1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `Meek_rule1` takes an object (graph) of the class `nx.DiGraph` as an input, and for any triple of variables from the graph, checks whether First Rule can be applied; if so, it orients the edges accordingly.\n",
    "\n",
    "*Hint:* the following methods from the `networkx` package can be useful:\n",
    "  - `to_numpy_array`\n",
    "  - `predecessors`\n",
    "  - `successors`\n",
    "  - `remove_edge`\n",
    "  - `neighbors`\n",
    "  \n",
    "Please look into the `networkx` package documentation for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Meek_rule1(graph):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        graph - causal graph (instance of nx.DiGraph)\n",
    "    Return:\n",
    "        graph - updated causal graph (instance of nx.DiGraph)\n",
    "        deleted_edges - list of tuples that represent the direct edges that were deleted, such as [(0, 1), (2, 3)]\n",
    "    \"\"\"\n",
    "    ############################################################################\n",
    "    # TODO: Apply the first Meek orientation rule to the graph and update the  #\n",
    "    #   edges accordingly.                                                     #\n",
    "    ############################################################################\n",
    "    # Replace \"...\" with your code\n",
    "\n",
    "    graph = ...\n",
    "    deleted_edges = ...\n",
    "\n",
    "    ############################################################################\n",
    "    #                               END OF YOUR CODE                           #\n",
    "    ############################################################################\n",
    "    \n",
    "    return graph, deleted_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second Rule**\\\n",
    "Assume there are three random variables $A$, $B$, $C$ such that\n",
    "- an edge between $A$ and $B$ is oriented from $A$ to $B$,\n",
    "- an edge between $B$ and $C$ is oriented from $B$ to $C$,\n",
    "- an edge between $A$ and $C$ is not oriented,\n",
    "\n",
    "then the edge between $A$ and $C$ can be oriented from $A$ to $C$. \n",
    "\n",
    "The following picture gives an illustration of this Second Rule.\\\n",
    "![](Rule2.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `Meek_rule2` takes an object (graph) of the class `nx.DiGraph` as an input, and for any triple of variables from the graph, checks whether Second Rule can be applied; if so, it orients the edges accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Meek_rule2(graph):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        graph - causal graph (instance of nx.DiGraph)\n",
    "    Return:\n",
    "        graph - updated causal graph (instance of nx.DiGraph)\n",
    "        deleted_edges - list of tuples that represent the direct edges that were deleted such as [(0, 1), (2, 3)]\n",
    "    \"\"\"\n",
    "    ############################################################################\n",
    "    # TODO: Apply the second Meek orientation rule to the graph and update the #\n",
    "    #   edges accordingly.                                                     #\n",
    "    ############################################################################\n",
    "    # Replace \"...\" with your code\n",
    "    \n",
    "    graph = ...\n",
    "    deleted_edges = ...\n",
    "    \n",
    "    ############################################################################\n",
    "    #                               END OF YOUR CODE                           #\n",
    "    ############################################################################\n",
    "    \n",
    "    return graph, deleted_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Third Rule**\\\n",
    "Assume there are four random variables $A$, $B$, $C$, $D$ such that\n",
    "- an edge between $A$ and $B$ is not oriented\n",
    "- an edge between $B$ and $C$ is oriented from $B$ to $C$\n",
    "- an edge between $C$ and $D$ is oriented from $D$ to $C$\n",
    "- an edge between $A$ and $D$ is not oriented\n",
    "- an edge between $A$ and $C$ is not oriented\n",
    "\n",
    "then the edge between $A$ and $C$ can be oriented from $A$ to $C$ \n",
    "\n",
    "The following picture gives an illustration of this Third Rule.\\\n",
    "![](Rule3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `Meek_rule3` takes an object (graph) of the class `nx.DiGraph` as an input, and for any 4-set of variables from the graph, checks whether Third Rule can be applied; if so, it orients the edges accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Meek_rule3(graph):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        graph - causal graph (instance of nx.DiGraph)\n",
    "    Return:\n",
    "        graph - updated causal graph (instance of nx.DiGraph)\n",
    "        deleted_edges - list of tuples that represent the direct edges that were deleted, such as [(0, 1), (2, 3)]\n",
    "    \"\"\"\n",
    "    ############################################################################\n",
    "    # TODO: Apply the third Meek orientation rule to the graph and update the  #\n",
    "    #   edges accordingly.                                                     #\n",
    "    ############################################################################\n",
    "    # Replace \"...\" with your code\n",
    "    \n",
    "    graph = ...\n",
    "    deleted_edges = ...\n",
    "\n",
    "    ############################################################################\n",
    "    #                               END OF YOUR CODE                           #\n",
    "    ############################################################################\n",
    "    \n",
    "    return graph, deleted_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PC algorithm\n",
    "We are now ready to implement our simplified PC algorithm built upon on the functions implemented above. The function `PC` takes as input a 2-dimensional array, where the columns represent features and rows represent the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PC(data, alpha):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        data - 2-dimensional np.array\n",
    "    Return:\n",
    "        graph - the resulting graph created by PC algorithm\n",
    "    \"\"\"\n",
    "    ############################################################################\n",
    "    # TODO: Implement a PC algorithm based on the functions implemented above  #\n",
    "    ############################################################################\n",
    "    # Replace \"...\" with your code\n",
    "    \n",
    "    # Initiailize a fully connected adjecency matrix for the random variables\n",
    "    n_vertices = ...\n",
    "    adj_matrix = ...\n",
    " \n",
    "    # Compute a correlation matrix between random variables\n",
    "    corr_matrix = ...\n",
    "    corr_matrix = np.nan_to_num(corr_matrix)\n",
    "\n",
    "    dependencies = dict()\n",
    "\n",
    "    # Delete edges based on the correlation matrix\n",
    "    adj_matrix = ...\n",
    "\n",
    "    # Identify the skeleton of over the random variables\n",
    "    adj_matrix, dependencies = ...\n",
    "            \n",
    "    # Identify v-structures in the graph and update adj_matrix accordingly\n",
    "    adj_matrix = ...\n",
    "\n",
    "    # Initialize the graph structure from the adjecency matrix\n",
    "    # Hint: use package networkx\n",
    "    graph =  ...\n",
    "\n",
    "\n",
    "    # Orient edges using all three Meek rules\n",
    "    graph, _ = ...\n",
    "    graph, _ = ...\n",
    "    graph, _ = ...\n",
    "\n",
    "    ############################################################################\n",
    "    #                               END OF YOUR CODE                           #\n",
    "    ############################################################################\n",
    "                \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on artificial data\n",
    "Let us test our implemented PC algorithm on some artificial data generated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1000\n",
    "eps_a = np.random.randn(n_samples)\n",
    "eps_b = np.random.randn(n_samples)\n",
    "eps_c = np.random.randn(n_samples)\n",
    "eps_d = np.random.randn(n_samples)\n",
    "eps_e = np.random.randn(n_samples)\n",
    "A = eps_a\n",
    "B = eps_b\n",
    "C = 3*A + 3*B\n",
    "D = eps_d + C\n",
    "E = eps_e + C\n",
    "data = np.hstack([A[:, None], B[:, None], C[:, None], D[:, None], E[:, None]])\n",
    "\n",
    "id_to_name = {key: name for key, name in enumerate([\"A\", \"B\", \"C\", \"D\", \"E\"])}\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "# Replace \"...\" with your code\n",
    "# Use the PC algorithm implemented before to find a causal graph that represents the given data\n",
    "graph  = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ellipsis' object has no attribute 'add_nodes_from'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gd/x2_9rfc50vscc01t_9cs5msm0000gp/T/ipykernel_47562/1917366777.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgraph_labeled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelabel_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_to_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcircular_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_labled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_networkx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_labeled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/networkx/relabel.py\u001b[0m in \u001b[0;36mrelabel_nodes\u001b[0;34m(G, mapping, copy)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_relabel_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_relabel_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/networkx/relabel.py\u001b[0m in \u001b[0;36m_relabel_copy\u001b[0;34m(G, mapping)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_relabel_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_nodes_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_multigraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ellipsis' object has no attribute 'add_nodes_from'"
     ]
    }
   ],
   "source": [
    "graph_labeled = nx.relabel_nodes(graph, id_to_name)\n",
    "pos = nx.circular_layout(graph_labled)\n",
    "nx.draw_networkx(graph_labeled, pos, with_labels=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What is the size of the Markov Equivalence class of the above graph?\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on real data\n",
    "We will now test our PC algorithm on a real dataset. Here we provide you with a code which uploads the dataset from the paper \"What Do College Ranking Data Tell Us About Student Retention?\" by Drudzel and Glymour. This dataset contains the following features:\n",
    "  - `spending_per_stdt` - total education and general expenses per student,\n",
    "  - `grad_rate` - average percentage of graduation,\n",
    "  - `stdt_clss_stndng` - class standing of the incoming freshmen,\n",
    "  - `rjct_rate` - rejection rate,\n",
    "  - `tst_scores` - average test scores of incoming students,\n",
    "  - `stdt_accept_rate` - pecentage of admitted students who accept university's offer,\n",
    "  - `stdt_tchr_ratio` - student teacher ratio,\n",
    "  - `fac_salary` - average faculty salary.\n",
    "\n",
    "For more details, you can look into the article. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.ccd.pitt.edu//wp-content/uploads/files/Retention.txt\"\n",
    "data = pd.read_csv(url, sep='\\s+')\n",
    "data_np = data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "id_to_name = {key: name for key, name in enumerate(data.columns)}\n",
    "# Replace \"...\" with your code\n",
    "# Use the PC algorithm implemented before to find a causal graph that represents the given data\n",
    "graph = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ellipsis' object has no attribute 'add_nodes_from'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gd/x2_9rfc50vscc01t_9cs5msm0000gp/T/ipykernel_47562/3920425001.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgraph_labeled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelabel_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_to_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcircular_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_labeled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_networkx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_labeled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/networkx/relabel.py\u001b[0m in \u001b[0;36mrelabel_nodes\u001b[0;34m(G, mapping, copy)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_relabel_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_relabel_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/networkx/relabel.py\u001b[0m in \u001b[0;36m_relabel_copy\u001b[0;34m(G, mapping)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_relabel_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_nodes_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_multigraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ellipsis' object has no attribute 'add_nodes_from'"
     ]
    }
   ],
   "source": [
    "graph_labeled = nx.relabel_nodes(graph, id_to_name)\n",
    "pos = nx.circular_layout(graph_labeled)\n",
    "nx.draw_networkx(graph_labeled, pos, with_labels=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Why are there some (one or more) bidirected edges in the graph? What does it mean?\n",
    "\n",
    "**Answer:**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
