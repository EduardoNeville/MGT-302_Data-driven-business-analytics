{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " !!! If you don't fill these fields, your homework does not count !!!<by/>\n",
    " #### first name and last name : Eduardo Neville\n",
    " #### sciper number : 314667\n",
    "  #### first name and last name : Åke Janson\n",
    " #### sciper number : 314487"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run cells by hitting `Shift` + `Enter` or `ctrl` + `Enter`. <br/>\n",
    "We highly recommend you to read each line of code carefully and try to understand what it exactly does. <br/>\n",
    "Just alter the parts that is between green comments and specified for you. Please do not change other parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soft margin SVM\n",
    "### about the Data:<br/>\n",
    "The purpose of this project is to classify tumors into malignant or benign. The following dataset is constructed based on images of tumors. Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.\n",
    "For more details about the features of this dataset you can visit this link:\n",
    "https://scikit-learn.org/stable/datasets/index.html#breast-cancer-dataset<br/>\n",
    "This dataset contains 30 features and 1 label that is called target. We should find a proper hyperplane that separates malignant and benign samples.\n",
    "The original dataset labels is 0 and 1 and in the following code boxes we change it to -1 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890     0.0  \n",
       "1          0.2750                  0.08902     0.0  \n",
       "2          0.3613                  0.08758     0.0  \n",
       "3          0.6638                  0.17300     0.0  \n",
       "4          0.2364                  0.07678     0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = load_breast_cancer()\n",
    "df = pd.DataFrame(np.c_[cancer[\"data\"], cancer[\"target\"]], columns = np.append(cancer[\"feature_names\"],[\"target\"]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.8804920913884 %\n",
      "71.8804920913884 %\n",
      "20.738137082601053 %\n",
      "20.738137082601053 %\n",
      "7.381370826010544 %\n",
      "7.381370826010544 %\n"
     ]
    }
   ],
   "source": [
    "cancer.target = np.where(cancer.target==0, -1, cancer.target) \n",
    "X_train ,X_test ,X_val ,y_train ,y_test ,y_val = None ,None ,None ,None ,None ,None\n",
    "################################################################################\n",
    "# TODO: using train_test_split package, split your data into 3 numpy array     #\n",
    "# called X_train, X_test, and X_val and also split the corresponding labels as #\n",
    "# y_train, y_test, and y_val. After spliting, the ratio of your data should be # \n",
    "# approximately like this:                                                     #\n",
    "#  Train : 72%     test : 20%       validation : 8%                            #\n",
    "################################################################################\n",
    "\n",
    "# Splitting the data into train, testing \n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target,train_size=0.72, random_state=42)\n",
    "# Splitting the testing set into testing and validation\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test,train_size=0.74, random_state=42)\n",
    "\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################\n",
    "print((X_train.shape[0]/cancer.data.shape[0]) * 100, \"%\")\n",
    "print((y_train.shape[0]/cancer.data.shape[0]) * 100, \"%\")\n",
    "print((X_test.shape[0]/cancer.data.shape[0]) * 100, \"%\")\n",
    "print((y_test.shape[0]/cancer.data.shape[0]) * 100, \"%\")\n",
    "print((X_val.shape[0]/cancer.data.shape[0]) * 100, \"%\")\n",
    "print((y_val.shape[0]/cancer.data.shape[0]) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### soft margin SVM optimization:<br/>\n",
    "We add 1 at the beginning of each Xs data (X_train, X_val , ...) and then the bias will be calculated implicitly.\n",
    "Then you should minimize the following SVM loss function (using gradient descent) with changing parameters of model.<br>\n",
    "In this notation: \n",
    "\\begin{equation}\n",
    "x_i , y_i\n",
    "\\end{equation}\n",
    "refers to feature vector of the sample and the label of our training data<br>\n",
    "and this is SVM loss function:\n",
    "\n",
    "\\begin{equation}\n",
    "\\large\n",
    "J(W) = \\frac{1}{N} \\sum_{i=1}^{N}{L^{(i)}} + \\frac{\\lambda}{2} ||W||^2\\\\\n",
    "\\large\n",
    "L^{(i)} ={max(0, 1 - y_i(w^{T}x_i)})\n",
    "\\;\\\\\n",
    "\\end{equation} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(409, 31)\n",
      "(42, 31)\n",
      "(118, 31)\n"
     ]
    }
   ],
   "source": [
    "# >>>>>WARNING: RUN THIS CELL ONLY ONCE!<<<<<\n",
    "\n",
    "# adding 1s to the end of feature vectors to be multiplied by bias term of weights\n",
    "X_val = np.insert(X_val, 0, 1, axis=1)\n",
    "X_train = np.insert(X_train, 0, 1, axis=1)\n",
    "X_test = np.insert(X_test, 0, 1, axis=1)\n",
    "print(X_train.shape)  \n",
    "print(X_val.shape)  \n",
    "print(X_test.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the following functions in SVM class. In the part that you should compute loss function of this class, you are not allowed to use \"for\" loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T16:30:29.561420Z",
     "start_time": "2020-03-12T16:30:29.538696Z"
    }
   },
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self, n_features: int, std: float):\n",
    "        \"\"\"\n",
    "        n_features: number of features in (or the dimension of) each instance\n",
    "        std: standard deviation used in the initialization of the weights of svm\n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        ################################################################################\n",
    "        # TODO: Initialize the weights of svm using random normal distribution with    #\n",
    "        # standard deviation equals to std.                                            #\n",
    "        ################################################################################\n",
    "\n",
    "        self.w = np.random.normal(loc=0, scale=std, size=n_features)\n",
    "\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################\n",
    "\n",
    "    def loss(self, X: np.ndarray, y: np.ndarray, reg_coeff: float):\n",
    "        \"\"\"\n",
    "        X: training instances as a 2d-array with shape (num_train, n_features)\n",
    "        y: labels corresponsing to the given training instances as a 1d-array with shape (num_train,)\n",
    "        reg_coeff: L2-regularization coefficient\n",
    "        \"\"\"\n",
    "        loss = 0.0\n",
    "        \n",
    "        #################################################################################\n",
    "        # TODO: Compute the hinge loss specified in the notebook and save it in the loss#                                                   # loss variable.                                                               #\n",
    "        # NOTE: YOU ARE NOT ALLOWED TO USE FOR LOOPS!                                   #\n",
    "        # Don't forget L2-regularization term in your implementation!                   #\n",
    "        #################################################################################\n",
    "        \n",
    "        # hinge loss\n",
    "        margins = y * np.dot(X, self.w)\n",
    "        loss = np.sum(np.maximum(0, 1 - margins))/self.n_features\n",
    "        \n",
    "        # add L2-regularization term\n",
    "        loss += 0.5 * reg_coeff * np.sum(self.w ** 2)\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################\n",
    "        return loss\n",
    "        \n",
    "    def update_weights(self,  X: np.ndarray, y: np.ndarray, learning_rate: float , reg_coeff: float):\n",
    "        \"\"\"\n",
    "        Updates the weights of the svm using the gradient of computed loss with respect to the weights. \n",
    "        learning_rate: learning rate that will be used in gradient descent to update the weights\n",
    "        \"\"\"\n",
    "        ################################################################################\n",
    "        # TODO: Compute the gradient of loss computed above w.r.t the svm weights.     #\n",
    "        # and then update self.w with the computed gradient.                           #\n",
    "        # (don't forget learning rate and reg_coeff in update rule)                    #\n",
    "        # Don't forget L2-regularization term in your implementation!                  #\n",
    "        ################################################################################\n",
    "        \n",
    "        # compute gradient\n",
    "        margins = y * np.dot(X, self.w)\n",
    "        misclassified = margins < 1\n",
    "        d_w = -np.dot(X[misclassified].T, y[misclassified])\n",
    "        d_w /= X.shape[0]\n",
    "        d_w += reg_coeff * self.w\n",
    "        \n",
    "        # update weights\n",
    "        self.w -= learning_rate * d_w\n",
    "\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        X: Numpy 2d-array of instances\n",
    "        \"\"\"\n",
    "        y_pred = None\n",
    "        ################################################################################\n",
    "        # TODO: predict the labels for the instances in X and save them in y_pred.     #                                      #\n",
    "        ################################################################################\n",
    "\n",
    "        y_pred = np.sign(np.dot(X, self.w))\n",
    "\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell contains your hyper parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = 0.0001\n",
    "num_iters = 20000\n",
    "reg_coeff = 20\n",
    "learning_rate=1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell using your SVM class, we want to train our model for cancer data:<br/>\n",
    "In every iteration you should see your training loss decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0, loss 13.435714, val acc 66.67%\n",
      "iteration 100, loss 13.031469, val acc 33.33%\n",
      "iteration 200, loss 12.641539, val acc 33.33%\n",
      "iteration 300, loss 12.463339, val acc 33.33%\n",
      "iteration 400, loss 12.399722, val acc 33.33%\n",
      "iteration 500, loss 12.375091, val acc 33.33%\n",
      "iteration 600, loss 12.354948, val acc 33.33%\n",
      "iteration 700, loss 12.335040, val acc 33.33%\n",
      "iteration 800, loss 12.315136, val acc 33.33%\n",
      "iteration 900, loss 12.295232, val acc 33.33%\n",
      "iteration 1000, loss 12.275328, val acc 33.33%\n",
      "iteration 1100, loss 12.255426, val acc 33.33%\n",
      "iteration 1200, loss 12.235524, val acc 33.33%\n",
      "iteration 1300, loss 12.215622, val acc 33.33%\n",
      "iteration 1400, loss 12.195720, val acc 33.33%\n",
      "iteration 1500, loss 12.175819, val acc 33.33%\n",
      "iteration 1600, loss 12.156181, val acc 33.33%\n",
      "iteration 1700, loss 12.136882, val acc 33.33%\n",
      "iteration 1800, loss 12.117718, val acc 33.33%\n",
      "iteration 1900, loss 12.098554, val acc 33.33%\n",
      "iteration 2000, loss 12.079591, val acc 33.33%\n",
      "iteration 2100, loss 12.061173, val acc 33.33%\n",
      "iteration 2200, loss 12.042837, val acc 33.33%\n",
      "iteration 2300, loss 12.024502, val acc 33.33%\n",
      "iteration 2400, loss 12.006168, val acc 33.33%\n",
      "iteration 2500, loss 11.988003, val acc 33.33%\n",
      "iteration 2600, loss 11.970290, val acc 33.33%\n",
      "iteration 2700, loss 11.952577, val acc 33.33%\n",
      "iteration 2800, loss 11.934865, val acc 33.33%\n",
      "iteration 2900, loss 11.917711, val acc 33.33%\n",
      "iteration 3000, loss 11.900809, val acc 33.33%\n",
      "iteration 3100, loss 11.883907, val acc 33.33%\n",
      "iteration 3200, loss 11.867005, val acc 33.33%\n",
      "iteration 3300, loss 11.850104, val acc 33.33%\n",
      "iteration 3400, loss 11.833203, val acc 33.33%\n",
      "iteration 3500, loss 11.816302, val acc 33.33%\n",
      "iteration 3600, loss 11.799402, val acc 33.33%\n",
      "iteration 3700, loss 11.782502, val acc 33.33%\n",
      "iteration 3800, loss 11.765780, val acc 33.33%\n",
      "iteration 3900, loss 11.749267, val acc 33.33%\n",
      "iteration 4000, loss 11.732756, val acc 33.33%\n",
      "iteration 4100, loss 11.716244, val acc 33.33%\n",
      "iteration 4200, loss 11.699733, val acc 33.33%\n",
      "iteration 4300, loss 11.683222, val acc 33.33%\n",
      "iteration 4400, loss 11.666712, val acc 33.33%\n",
      "iteration 4500, loss 11.650202, val acc 33.33%\n",
      "iteration 4600, loss 11.633692, val acc 33.33%\n",
      "iteration 4700, loss 11.617183, val acc 33.33%\n",
      "iteration 4800, loss 11.600674, val acc 33.33%\n",
      "iteration 4900, loss 11.584165, val acc 33.33%\n",
      "iteration 5000, loss 11.567657, val acc 33.33%\n",
      "iteration 5100, loss 11.551149, val acc 33.33%\n",
      "iteration 5200, loss 11.534641, val acc 33.33%\n",
      "iteration 5300, loss 11.518134, val acc 33.33%\n",
      "iteration 5400, loss 11.501627, val acc 33.33%\n",
      "iteration 5500, loss 11.485120, val acc 33.33%\n",
      "iteration 5600, loss 11.468614, val acc 33.33%\n",
      "iteration 5700, loss 11.452108, val acc 33.33%\n",
      "iteration 5800, loss 11.435603, val acc 33.33%\n",
      "iteration 5900, loss 11.419098, val acc 33.33%\n",
      "iteration 6000, loss 11.402615, val acc 33.33%\n",
      "iteration 6100, loss 11.386134, val acc 33.33%\n",
      "iteration 6200, loss 11.369676, val acc 33.33%\n",
      "iteration 6300, loss 11.353397, val acc 33.33%\n",
      "iteration 6400, loss 11.337117, val acc 33.33%\n",
      "iteration 6500, loss 11.320839, val acc 33.33%\n",
      "iteration 6600, loss 11.304560, val acc 35.71%\n",
      "iteration 6700, loss 11.288282, val acc 35.71%\n",
      "iteration 6800, loss 11.272004, val acc 35.71%\n",
      "iteration 6900, loss 11.255726, val acc 35.71%\n",
      "iteration 7000, loss 11.239449, val acc 35.71%\n",
      "iteration 7100, loss 11.223172, val acc 35.71%\n",
      "iteration 7200, loss 11.206896, val acc 35.71%\n",
      "iteration 7300, loss 11.190620, val acc 35.71%\n",
      "iteration 7400, loss 11.174344, val acc 35.71%\n",
      "iteration 7500, loss 11.158069, val acc 38.10%\n",
      "iteration 7600, loss 11.141794, val acc 38.10%\n",
      "iteration 7700, loss 11.125519, val acc 38.10%\n",
      "iteration 7800, loss 11.109245, val acc 42.86%\n",
      "iteration 7900, loss 11.092971, val acc 45.24%\n",
      "iteration 8000, loss 11.076697, val acc 45.24%\n",
      "iteration 8100, loss 11.060424, val acc 45.24%\n",
      "iteration 8200, loss 11.044151, val acc 47.62%\n",
      "iteration 8300, loss 11.027878, val acc 50.00%\n",
      "iteration 8400, loss 11.011606, val acc 50.00%\n",
      "iteration 8500, loss 10.995334, val acc 54.76%\n",
      "iteration 8600, loss 10.979062, val acc 54.76%\n",
      "iteration 8700, loss 10.962791, val acc 54.76%\n",
      "iteration 8800, loss 10.946520, val acc 54.76%\n",
      "iteration 8900, loss 10.930250, val acc 57.14%\n",
      "iteration 9000, loss 10.913980, val acc 59.52%\n",
      "iteration 9100, loss 10.897710, val acc 61.90%\n",
      "iteration 9200, loss 10.881440, val acc 61.90%\n",
      "iteration 9300, loss 10.865171, val acc 61.90%\n",
      "iteration 9400, loss 10.848902, val acc 64.29%\n",
      "iteration 9500, loss 10.832634, val acc 66.67%\n",
      "iteration 9600, loss 10.816366, val acc 66.67%\n",
      "iteration 9700, loss 10.800098, val acc 69.05%\n",
      "iteration 9800, loss 10.783831, val acc 69.05%\n",
      "iteration 9900, loss 10.767564, val acc 69.05%\n",
      "iteration 10000, loss 10.751297, val acc 69.05%\n",
      "iteration 10100, loss 10.735031, val acc 69.05%\n",
      "iteration 10200, loss 10.718765, val acc 69.05%\n",
      "iteration 10300, loss 10.702499, val acc 69.05%\n",
      "iteration 10400, loss 10.686234, val acc 69.05%\n",
      "iteration 10500, loss 10.669969, val acc 71.43%\n",
      "iteration 10600, loss 10.653705, val acc 76.19%\n",
      "iteration 10700, loss 10.637440, val acc 78.57%\n",
      "iteration 10800, loss 10.621177, val acc 80.95%\n",
      "iteration 10900, loss 10.604913, val acc 85.71%\n",
      "iteration 11000, loss 10.588650, val acc 85.71%\n",
      "iteration 11100, loss 10.572387, val acc 85.71%\n",
      "iteration 11200, loss 10.556125, val acc 85.71%\n",
      "iteration 11300, loss 10.539863, val acc 85.71%\n",
      "iteration 11400, loss 10.523642, val acc 83.33%\n",
      "iteration 11500, loss 10.507423, val acc 83.33%\n",
      "iteration 11600, loss 10.491204, val acc 83.33%\n",
      "iteration 11700, loss 10.474985, val acc 88.10%\n",
      "iteration 11800, loss 10.458872, val acc 88.10%\n",
      "iteration 11900, loss 10.442801, val acc 88.10%\n",
      "iteration 12000, loss 10.426729, val acc 88.10%\n",
      "iteration 12100, loss 10.410657, val acc 88.10%\n",
      "iteration 12200, loss 10.394587, val acc 90.48%\n",
      "iteration 12300, loss 10.378517, val acc 92.86%\n",
      "iteration 12400, loss 10.362447, val acc 92.86%\n",
      "iteration 12500, loss 10.346377, val acc 92.86%\n",
      "iteration 12600, loss 10.330308, val acc 92.86%\n",
      "iteration 12700, loss 10.314239, val acc 92.86%\n",
      "iteration 12800, loss 10.298170, val acc 92.86%\n",
      "iteration 12900, loss 10.282102, val acc 92.86%\n",
      "iteration 13000, loss 10.266034, val acc 92.86%\n",
      "iteration 13100, loss 10.249967, val acc 92.86%\n",
      "iteration 13200, loss 10.233900, val acc 92.86%\n",
      "iteration 13300, loss 10.217833, val acc 92.86%\n",
      "iteration 13400, loss 10.201766, val acc 92.86%\n",
      "iteration 13500, loss 10.185700, val acc 92.86%\n",
      "iteration 13600, loss 10.169634, val acc 92.86%\n",
      "iteration 13700, loss 10.153568, val acc 92.86%\n",
      "iteration 13800, loss 10.137504, val acc 92.86%\n",
      "iteration 13900, loss 10.121439, val acc 92.86%\n",
      "iteration 14000, loss 10.105375, val acc 92.86%\n",
      "iteration 14100, loss 10.089311, val acc 92.86%\n",
      "iteration 14200, loss 10.073247, val acc 92.86%\n",
      "iteration 14300, loss 10.057183, val acc 92.86%\n",
      "iteration 14400, loss 10.041120, val acc 92.86%\n",
      "iteration 14500, loss 10.025057, val acc 92.86%\n",
      "iteration 14600, loss 10.008995, val acc 92.86%\n",
      "iteration 14700, loss 9.992933, val acc 92.86%\n",
      "iteration 14800, loss 9.976872, val acc 92.86%\n",
      "iteration 14900, loss 9.960810, val acc 95.24%\n",
      "iteration 15000, loss 9.944749, val acc 95.24%\n",
      "iteration 15100, loss 9.928688, val acc 95.24%\n",
      "iteration 15200, loss 9.912628, val acc 95.24%\n",
      "iteration 15300, loss 9.896568, val acc 95.24%\n",
      "iteration 15400, loss 9.880509, val acc 95.24%\n",
      "iteration 15500, loss 9.864450, val acc 95.24%\n",
      "iteration 15600, loss 9.848391, val acc 95.24%\n",
      "iteration 15700, loss 9.832332, val acc 95.24%\n",
      "iteration 15800, loss 9.816273, val acc 95.24%\n",
      "iteration 15900, loss 9.800216, val acc 95.24%\n",
      "iteration 16000, loss 9.784158, val acc 95.24%\n",
      "iteration 16100, loss 9.768101, val acc 95.24%\n",
      "iteration 16200, loss 9.752045, val acc 95.24%\n",
      "iteration 16300, loss 9.735988, val acc 95.24%\n",
      "iteration 16400, loss 9.719932, val acc 95.24%\n",
      "iteration 16500, loss 9.703875, val acc 95.24%\n",
      "iteration 16600, loss 9.687820, val acc 95.24%\n",
      "iteration 16700, loss 9.671765, val acc 95.24%\n",
      "iteration 16800, loss 9.655711, val acc 95.24%\n",
      "iteration 16900, loss 9.639656, val acc 95.24%\n",
      "iteration 17000, loss 9.623602, val acc 95.24%\n",
      "iteration 17100, loss 9.607548, val acc 95.24%\n",
      "iteration 17200, loss 9.591495, val acc 95.24%\n",
      "iteration 17300, loss 9.575441, val acc 95.24%\n",
      "iteration 17400, loss 9.559389, val acc 95.24%\n",
      "iteration 17500, loss 9.543337, val acc 95.24%\n",
      "iteration 17600, loss 9.527285, val acc 95.24%\n",
      "iteration 17700, loss 9.511234, val acc 95.24%\n",
      "iteration 17800, loss 9.495182, val acc 95.24%\n",
      "iteration 17900, loss 9.479131, val acc 95.24%\n",
      "iteration 18000, loss 9.463080, val acc 95.24%\n",
      "iteration 18100, loss 9.447030, val acc 95.24%\n",
      "iteration 18200, loss 9.430980, val acc 95.24%\n",
      "iteration 18300, loss 9.414931, val acc 95.24%\n",
      "iteration 18400, loss 9.398882, val acc 95.24%\n",
      "iteration 18500, loss 9.382833, val acc 95.24%\n",
      "iteration 18600, loss 9.366784, val acc 95.24%\n",
      "iteration 18700, loss 9.350735, val acc 95.24%\n",
      "iteration 18800, loss 9.334687, val acc 95.24%\n",
      "iteration 18900, loss 9.318640, val acc 95.24%\n",
      "iteration 19000, loss 9.302593, val acc 95.24%\n",
      "iteration 19100, loss 9.286547, val acc 95.24%\n",
      "iteration 19200, loss 9.270500, val acc 95.24%\n",
      "iteration 19300, loss 9.254454, val acc 95.24%\n",
      "iteration 19400, loss 9.238408, val acc 95.24%\n",
      "iteration 19500, loss 9.222362, val acc 95.24%\n",
      "iteration 19600, loss 9.206317, val acc 95.24%\n",
      "iteration 19700, loss 9.190273, val acc 95.24%\n",
      "iteration 19800, loss 9.174228, val acc 95.24%\n",
      "iteration 19900, loss 9.158185, val acc 95.24%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "model = SVM(n_features=X_train.shape[1], std= std )\n",
    "loss_history = []\n",
    "loss_val_history = []\n",
    "for it in range(num_iters):\n",
    "    loss = model.loss(X_train, y_train, reg_coeff)\n",
    "    loss_val = model.loss(X_val, y_val, reg_coeff)\n",
    "    if it % 100 == 0:\n",
    "        val_preds =  model.predict(X_val)\n",
    "        print('iteration %d, loss %f, val acc %.2f%%' % (it, loss,  accuracy_score(y_val,val_preds) * 100))\n",
    "    model.update_weights(X_train, y_train, learning_rate , reg_coeff)\n",
    "    loss_history.append(loss)\n",
    "    loss_val_history.append(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "####################################################################################\n",
    "# TODO: using matplotlib.pyplot package plot the training loss and validation loss #\n",
    "# using loss_loss_history and loss_val_history                                     #\n",
    "####################################################################################\n",
    "\n",
    "plt.plot(loss_history, label='training loss')\n",
    "plt.plot(loss_val_history, label='validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "####################################################################################\n",
    "#                                 END OF YOUR CODE                                 #\n",
    "####################################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1:\n",
    "With changing your hyper parameters, find a configuration of hyper parameters that cause your loss to increase after each iteration and then report that configuration in the next cell. Explain why our loss increases?\n",
    "Write your answer in \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The reason for the loss to increase is that the regularization term in the loss function dominates the hinge loss term. With a high regularization coefficient, the SVM tries to minimize the norm of the weights, which results in setting the weights to small values. Since the hinge loss term is not minimized, the SVM does not correctly classify the training examples, leading to an increase in the loss function. Also, the learning rate is high enough to cause significant weight updates in each iteration, leading to overshooting the optimal solution.\n",
    "\n",
    "In summary, the above hyperparameters cause the SVM to overfit the training data, leading to high values of regularization and low values of hinge loss, which results in misclassification of training examples and a continuous increase in the loss function.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "std = \"0.001\" <br>\n",
    "num_iters = \"1000\"<br>\n",
    "reg_coeff = \"100\"<br>\n",
    "learning_rate = \"0.01\"<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
